# ðŸ›¡ï¸ SOC Security Data Pipeline & Dashboard

> **CYNA â€“ Data Engineer Internship Technical Test**


## Overview

This project simulates a Security Operations Center (SOC) data pipeline.

The goal is to:

- collect security logs,

- enrich them using threat intelligence,

- and visualize the results in a dashboard that helps SOC analysts understand what is happening in the network.

The focus of this project is clarity, correctness, and realistic design choices, rather than building an overly complex system.

---

##  Architecture
---
<img width="2286" height="1110" alt="image" src="https://github.com/user-attachments/assets/f7db365e-bc19-4de9-a4ca-c11123179ab3" />

---
##  Running the Project
````md
````
1. Create a virtual environment
````
python -m venv .venv
source .venv/bin/activate   # macOS / Linux
.venv\Scripts\activate      # Windows
````

#### 2. Install dependencies

```bash
pip install -r requirements.txt
```

#### 3. Run the data pipeline

```bash
python main.py
```

#### 4. Start the dashboard

```bash
streamlit run dashboards/app.py
```
Open in browser:
```bash
http://localhost:8501
```
---
## Note: 
In the local both backend and steamlit is running inside the (.venv) .

## Steamlit Frontend
-  cd cyna-data-engineering-test 
-  python -m venv .venv
- .venv\Scripts\activate
- streamlit run dashboards/app.py

---
## Option 1: Run Backend Pipeline in Local
- cd cyna-data-engineering-test
- **Check whether its inside (.venv) or not, if it is the run.**
- python main.py 
 
##  Option 2: Run Backend Pipeline with Docker
- cd cyna-data-engineering-test
- docker compose up --build  **(No need to run inside .venv)**
 

---

### What This Project Does
The system performs three core security data tasks:

- Ingest security logs generated by an IDS log generator

- Ingest threat intelligence data (malicious IP list)

- Enrich and analyze the data, then display insights in a dashboard
---

## Tech Stack

- **Language:**   Python  
- **Database:**   DuckDB  
- **Data Processing:**   Pandas, SQL  
- **Threat Intelligence:** IPSUM  
- **Dashboard:** Streamlit, Plotly  
- **Log Generation:** Security Log Generator  
- **Containerization:** Docker  

---

## Data Pipeline

### Log Ingestion
- Parse raw IDS logs
- Normalize timestamps
- Store structured data in `raw_logs`

### Threat Intelligence Ingestion
- Load IPSUM feed
- Store data in `threat_ips`

### Enrichment
- Match `src_ip` / `dst_ip` against threat intelligence
- Flag malicious events
- Attach confidence score

Final dataset: `enriched_logs`

---

## SOC Dashboard

Designed for **real SOC usage**, not just visualization.

### Key Metrics
- Total events  
- Malicious events  
- Benign events  

### Visualizations
- Severity distribution  
- Protocol usage  
- Event timeline  
- Top destination assets  
- Malicious IP analysis  

### Filters
- Date range  
- Severity  
- Protocol  

---


## What Was Achieved

#### 1. What Works

- IDS logs are successfully ingested and parsed

- Threat intelligence data is loaded correctly

- Logs are enriched using IP reputation matching

- Enriched data is stored in an analytical database

- A SOC-style dashboard displays meaningful security insights

- The project runs both locally and via Docker

---

## What Insights the Dashboard Provides

The dashboard allows a SOC analyst to:

- Monitor the overall volume of security events

- Identify potentially malicious traffic

- See which destination systems are most targeted

- Analyze severity and protocol distributions

- Investigate malicious events in detail when they appear

- Filter events by date, severity, and protocol
---
## Challenges Faced

Malicious Event Detection :
- One challenge I faced was correctly identifying malicious events during the enrichment step.
After manually adding a known malicious IP to the ids.log file, the total number of events increased as expected, but the dashboard still showed zero malicious events. Since ingestion and storage were working correctly, the issue was not immediately obvious.
After investigation, I found that the problem was in the SQL join logic used to enrich logs with threat intelligence. The query did not correctly handle cases where either the source IP or destination IP matched a malicious IP.
I fixed this by updating the enrichment query to check both src_ip and dst_ip against the threat intelligence table and correctly propagate the confidence score. After this change, malicious events were correctly flagged and appeared in the dashboard.

Data Freshness Between Pipeline and Dashboard :
- Another challenge was ensuring the dashboard always reflected the latest data after the backend pipeline was re-run. At times, the dashboard continued to display old values because it was reading from an existing DuckDB file while Streamlit does not automatically re-trigger ingestion.
This was resolved by clearly separating responsibilities: the backend pipeline handles ingestion and enrichment, while the dashboard remains read-only. I also removed unnecessary caching to ensure the dashboard always reads the current database state after each pipeline run.

Batch Processing vs Real-Time Streaming :
- One challenge in this project is that the system works in batch mode rather than real time. Logs are generated and stored in files, and they are only processed when the backend pipeline is executed.Because of this, the dashboard does not update automatically when new logs are added unless the ingestion step is run again.
I chose this approach intentionally because it is simpler, more stable, and easier to reason about within the scope of this technical test. With more time and infrastructure, this could be improved by using real-time streaming tools like Kafka, but for this project, batch processing was the most realistic and reliable choice.

Designing a Realistic SOC Dashboard :
- Making the dashboard look professional and SOC like was also challenging. Streamlit dashboards can easily appear demo-like if not designed carefully.
To address this, I focused on clarity and realism by using neutral colors, limiting red to threat-related signals, and structuring the dashboard into clear sections for overview, prioritization, and investigation. This resulted in a dashboard that is readable, calm, and aligned with how SOC analysts typically consume security data.


## What is not done yet

- No Real-Time Streaming (Batch Processing Only)

- No Automated Log Generator Integration

- No Multi-Source Log Support (IDS Logs Only)

---
---
## Dashboard Behavior (Malicious Events)
<img width="1074" height="238" alt="image" src="https://github.com/user-attachments/assets/15f074a6-23eb-4dda-ab01-3776a6f82d57" />

At the moment, the dashboard may show 0 Malicious Events.
This is expected behavior and does not indicate a problem.

This happens when none of the IP addresses in ids.log match the IPs present in the IPSUM threat intelligence dataset.

In this system, an event is marked as malicious only if the source IP or destination IP exists in the IPSUM dataset. If there is no match, the event is treated as benign.

To confirm that the detection and enrichment logic works correctly, I tested the pipeline by manually adding a known malicious IP from the IPSUM dataset into the IDS logs.

## Example Test Log
```bash
2026-02-06 12:00:00,000 - ids_logger_1 - high_severity - TCP - 213.209.159.158:4444 --> 10.0.0.10:80 - SYN - Malicious traffic

```
The IP address 213.209.159.158 exists in the IPSUM dataset with a confidence level of 11.

After rerunning the backend pipeline:

- The event was correctly flagged as malicious

- The Malicious Events count increased

- Malicious IPs, the heatmap, and event details appeared in the dashboard

